# CSE573-Fake Review Detection Group 6
 CSE573 Fake Review Detection


# Dataset

[Amazon Data Set](https://github.com/adityasinha0523/CSE573-Fake-Review-Detection-Group-6/blob/main/DATA)



# Classification Algorithms

Utilized different classification Algorithms


## SVM

### TF-IDF

| Accuracy | Precision | Recall | F1-Score |
| -------- | --------- | ------ | -------- |
| 85.65%   |   85.66%  | 98.12% |  92.25%  |




## Multinominal Naive Bayes

### TF-IDF

| Accuracy | Precision | Recall | F1-Score |
| -------- | --------- | ------ | -------- |
| 85.65%   |   85.66%  | 98.12% |  92.25%  |



## Logistic Regression

### TF-IDF

| Accuracy | Precision | Recall | F1-Score |
| -------- | --------- | ------ | -------- |
| 85.65%   |   85.66%  | 98.12% |  92.25%  |



# Deep learning



* ## BERT

BERT base model

The BERT (Bidirectional Encoder Representations from Transformers) base model represents a significant breakthrough in the field of natural language processing (NLP). Developed by Google, it stands out for its ability to understand the context of a word in a sentence by analyzing the words that come before and after it, a method known as bidirectional training. This is a departure from previous models that typically processed text in one direction, either left-to-right or right-to-left. BERT base consists of 12 layers (transformer blocks), 768 hidden units, and 12 attention heads, totaling 110 million parameters. This structure enables it to handle a wide range of NLP tasks, such as question answering, language inference, and sentiment analysis, with remarkable effectiveness. Its pre-training on a large corpus of text, followed by fine-tuning for specific tasks, allows it to achieve state-of-the-art results across various benchmarks.





| Accuracy | Precision | Recall | F1-Score |
| -------- | --------- | ------ | -------- |
| 86.87%   | 87.76%    | 98.62% | 92.87%   |



<br />

â€‹                   


* ## RoBERTa

 RoBERTa base model







| Accuracy | Precision | Recall | F1-Score |
| -------- | --------- | ------ | -------- |
| 86.99%   |  87.78%   | 98.74% |  92.94%  |

<br />

* ## Feed Forward

 RoBERTa base model







| Accuracy | Precision | Recall | F1-Score |
| -------- | --------- | ------ | -------- |
| 86.99%   |  87.78%   | 98.74% |  92.94%  |

<br />

* ## XLMBERT

XLMBERT  model







| Accuracy | Precision | Recall | F1-Score |
| -------- | --------- | ------ | -------- |
| 86.99%   |  87.78%   | 98.74% |  92.94%  |

<br />